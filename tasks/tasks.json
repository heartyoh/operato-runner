{
  "tasks": [
    {
      "id": 1,
      "title": "Define Core Data Models",
      "description": "Create the foundational data models for the system including Module, ExecRequest, and ExecResult as specified in the PRD.",
      "details": "Create Python classes or Pydantic models for:\n1. Module: name, env, path/code, created_at, version, tags\n2. ExecRequest: module, input_json\n3. ExecResult: result_json, exit_code, stderr, duration\n\nImplement serialization/deserialization methods for JSON and potentially protobuf compatibility. Use Pydantic for validation and FastAPI integration.\n\nExample Module model:\n```python\nfrom pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any, List\n\nclass Module(BaseModel):\n    name: str\n    env: str  # 'inline', 'venv', 'conda', 'docker'\n    code: Optional[str] = None\n    path: Optional[str] = None\n    created_at: datetime = datetime.now()\n    version: str = \"0.1.0\"\n    tags: List[str] = []\n    \n    def __str__(self) -> str:\n        return f\"Module({self.name}, {self.env}, v{self.version})\"\n```",
      "testStrategy": "Write unit tests for each model to verify:\n1. Object creation with valid parameters\n2. Validation errors for invalid inputs\n3. Serialization to/from JSON\n4. Default value handling\n5. String representation\n\nUse pytest for testing framework.",
      "priority": "high",
      "dependencies": [],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 2,
      "title": "Implement Executor Interface",
      "description": "Define the base Executor interface that all specific executors will implement, establishing the contract for Python module execution.",
      "details": "Create an abstract base class for Executor with the following methods:\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom .models import ExecRequest, ExecResult\n\nclass Executor(ABC):\n    @abstractmethod\n    async def execute(self, request: ExecRequest) -> ExecResult:\n        \"\"\"Execute the module with the given input and return the result\"\"\"\n        pass\n        \n    @abstractmethod\n    async def validate(self, module_name: str) -> bool:\n        \"\"\"Validate if this executor can run the specified module\"\"\"\n        pass\n        \n    @abstractmethod\n    async def cleanup(self) -> None:\n        \"\"\"Clean up any resources used by this executor\"\"\"\n        pass\n        \n    @property\n    @abstractmethod\n    def executor_type(self) -> str:\n        \"\"\"Return the type of this executor (inline, venv, conda, docker)\"\"\"\n        pass\n```\n\nThis interface will ensure all executors implement the required functionality while allowing for specialized behavior in each implementation.",
      "testStrategy": "Create a mock executor implementation for testing. Verify that:\n1. Abstract methods cannot be instantiated directly\n2. Concrete implementations must provide all required methods\n3. The interface correctly defines the contract between ExecutorManager and specific executors",
      "priority": "high",
      "dependencies": [
        1
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 3,
      "title": "Implement InlineExecutor",
      "description": "Create the InlineExecutor that runs Python code directly in the current process with appropriate sandboxing.",
      "details": "Implement the InlineExecutor class that inherits from the Executor interface:\n\n```python\nimport ast\nimport sys\nfrom io import StringIO\nfrom typing import Dict, Any\nfrom .executor import Executor\nfrom .models import ExecRequest, ExecResult\nimport time\n\nclass InlineExecutor(Executor):\n    def __init__(self):\n        self.executor_type = \"inline\"\n    \n    async def validate(self, module_name: str) -> bool:\n        # Check if module exists in registry and is of type 'inline'\n        # Implementation depends on ModuleRegistry\n        return True  # Placeholder\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        start_time = time.time()\n        # Get module code from registry\n        code = \"\"  # Placeholder, will come from ModuleRegistry\n        \n        # Capture stdout/stderr\n        old_stdout, old_stderr = sys.stdout, sys.stderr\n        stdout_capture, stderr_capture = StringIO(), StringIO()\n        sys.stdout, sys.stderr = stdout_capture, stderr_capture\n        \n        result_json = {}\n        exit_code = 0\n        \n        try:\n            # Basic security check (can be enhanced with RestrictedPython)\n            ast.parse(code)  # Will raise SyntaxError if code is invalid\n            \n            # Create namespace for execution\n            namespace = {\"input\": request.input_json}\n            \n            # Execute code\n            exec(code, namespace)\n            \n            # Extract handler result\n            if \"handler\" in namespace and callable(namespace[\"handler\"]):\n                result_json = namespace[\"handler\"](request.input_json)\n            else:\n                raise ValueError(\"Module must define a handler function\")\n                \n        except Exception as e:\n            exit_code = 1\n            print(f\"Error executing module: {str(e)}\", file=sys.stderr)\n        finally:\n            # Restore stdout/stderr\n            sys.stdout, sys.stderr = old_stdout, old_stderr\n        \n        duration = time.time() - start_time\n        \n        return ExecResult(\n            result_json=result_json,\n            exit_code=exit_code,\n            stderr=stderr_capture.getvalue(),\n            stdout=stdout_capture.getvalue(),\n            duration=duration\n        )\n    \n    async def cleanup(self) -> None:\n        # Nothing to clean up for inline executor\n        pass\n        \n    @property\n    def executor_type(self) -> str:\n        return \"inline\"\n```\n\nConsider enhancing security with RestrictedPython or similar libraries to sandbox the execution environment.",
      "testStrategy": "Write unit tests to verify:\n1. Successful execution of valid Python code\n2. Proper error handling for invalid code\n3. Correct capture of stdout/stderr\n4. Accurate timing measurement\n5. Security measures prevent dangerous operations\n6. Handler function is correctly called with input\n7. Result is properly formatted",
      "priority": "high",
      "dependencies": [
        1,
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 4,
      "title": "Implement VenvExecutor",
      "description": "Create the VenvExecutor that runs Python code in isolated virtual environments.",
      "details": "Implement the VenvExecutor class that runs code in Python virtual environments:\n\n```python\nimport os\nimport subprocess\nimport tempfile\nimport json\nimport time\nfrom typing import Dict, Any\nfrom .executor import Executor\nfrom .models import ExecRequest, ExecResult\n\nclass VenvExecutor(Executor):\n    def __init__(self, venv_path=\"./venvs\"):\n        self.venv_path = venv_path\n        os.makedirs(venv_path, exist_ok=True)\n    \n    async def validate(self, module_name: str) -> bool:\n        # Check if module exists and is of type 'venv'\n        # Also verify the venv exists\n        venv_dir = os.path.join(self.venv_path, module_name)\n        return os.path.exists(venv_dir)\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        start_time = time.time()\n        module_name = request.module\n        venv_dir = os.path.join(self.venv_path, module_name)\n        \n        # Create temporary file for input JSON\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as input_file:\n            json.dump(request.input_json, input_file)\n            input_path = input_file.name\n        \n        # Create temporary file for output\n        output_path = tempfile.mktemp(suffix='.json')\n        \n        # Get module path from registry\n        module_path = \"\"  # Placeholder, will come from ModuleRegistry\n        \n        # Prepare the Python command to run in the venv\n        if os.name == 'nt':  # Windows\n            python_bin = os.path.join(venv_dir, 'Scripts', 'python.exe')\n        else:  # Unix/Linux\n            python_bin = os.path.join(venv_dir, 'bin', 'python')\n        \n        # Command to execute the module\n        cmd = [\n            python_bin,\n            '-c',\n            f\"import json; import sys; sys.path.append('{os.path.dirname(module_path)}'); \"\n            f\"from {os.path.basename(module_path).replace('.py', '')} import handler; \"\n            f\"with open('{input_path}', 'r') as f: input_data = json.load(f); \"\n            f\"result = handler(input_data); \"\n            f\"with open('{output_path}', 'w') as f: json.dump(result, f)\"\n        ]\n        \n        try:\n            # Execute the command\n            process = subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                timeout=60  # 1 minute timeout\n            )\n            \n            # Read the output\n            if os.path.exists(output_path):\n                with open(output_path, 'r') as f:\n                    result_json = json.load(f)\n            else:\n                result_json = {}\n                \n            exit_code = process.returncode\n            stderr = process.stderr\n            stdout = process.stdout\n            \n        except subprocess.TimeoutExpired:\n            exit_code = 124  # Standard timeout exit code\n            stderr = \"Execution timed out after 60 seconds\"\n            stdout = \"\"\n            result_json = {}\n        except Exception as e:\n            exit_code = 1\n            stderr = f\"Error executing module: {str(e)}\"\n            stdout = \"\"\n            result_json = {}\n        finally:\n            # Clean up temporary files\n            if os.path.exists(input_path):\n                os.unlink(input_path)\n            if os.path.exists(output_path):\n                os.unlink(output_path)\n        \n        duration = time.time() - start_time\n        \n        return ExecResult(\n            result_json=result_json,\n            exit_code=exit_code,\n            stderr=stderr,\n            stdout=stdout,\n            duration=duration\n        )\n    \n    async def cleanup(self) -> None:\n        # Nothing to do for cleanup in this implementation\n        # Could add venv cleanup logic if needed\n        pass\n        \n    @property\n    def executor_type(self) -> str:\n        return \"venv\"\n```\n\nThis implementation assumes that virtual environments are pre-created for each module. You may want to add functionality to create venvs on-demand and install requirements.",
      "testStrategy": "Write integration tests to verify:\n1. Execution in isolated virtual environments\n2. Proper handling of dependencies within the venv\n3. Correct passing of input/output between main process and venv\n4. Timeout handling for long-running processes\n5. Error handling for missing venvs or modules\n6. Resource cleanup after execution",
      "priority": "medium",
      "dependencies": [
        1,
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 5,
      "title": "Implement ModuleRegistry",
      "description": "Create the ModuleRegistry component that manages registered modules with YAML file persistence.",
      "details": "Implement the ModuleRegistry class to manage module registration and retrieval:\n\n```python\nimport os\nimport yaml\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\nfrom .models import Module\n\nclass ModuleRegistry:\n    def __init__(self, config_path=\"./modules.yaml\"):\n        self.config_path = config_path\n        self.modules: Dict[str, Module] = {}\n        self._load_modules()\n    \n    def _load_modules(self) -> None:\n        \"\"\"Load modules from YAML file\"\"\"\n        if os.path.exists(self.config_path):\n            try:\n                with open(self.config_path, 'r') as f:\n                    modules_data = yaml.safe_load(f) or {}\n                \n                for name, data in modules_data.items():\n                    # Convert YAML data to Module object\n                    self.modules[name] = Module(\n                        name=name,\n                        env=data.get('env', 'inline'),\n                        code=data.get('code'),\n                        path=data.get('path'),\n                        created_at=datetime.fromisoformat(data.get('created_at', datetime.now().isoformat())),\n                        version=data.get('version', '0.1.0'),\n                        tags=data.get('tags', [])\n                    )\n            except Exception as e:\n                print(f\"Error loading modules: {str(e)}\")\n    \n    def _save_modules(self) -> None:\n        \"\"\"Save modules to YAML file\"\"\"\n        modules_data = {}\n        for name, module in self.modules.items():\n            modules_data[name] = {\n                'env': module.env,\n                'code': module.code,\n                'path': module.path,\n                'created_at': module.created_at.isoformat(),\n                'version': module.version,\n                'tags': module.tags\n            }\n        \n        with open(self.config_path, 'w') as f:\n            yaml.dump(modules_data, f)\n    \n    def get_module(self, name: str) -> Optional[Module]:\n        \"\"\"Get a module by name\"\"\"\n        return self.modules.get(name)\n    \n    def list_modules(self) -> List[Module]:\n        \"\"\"List all registered modules\"\"\"\n        return list(self.modules.values())\n    \n    def register_module(self, module: Module) -> None:\n        \"\"\"Register a new module or update existing one\"\"\"\n        self.modules[module.name] = module\n        self._save_modules()\n    \n    def delete_module(self, name: str) -> bool:\n        \"\"\"Delete a module by name\"\"\"\n        if name in self.modules:\n            del self.modules[name]\n            self._save_modules()\n            return True\n        return False\n    \n    def get_modules_by_env(self, env: str) -> List[Module]:\n        \"\"\"Get all modules for a specific environment\"\"\"\n        return [m for m in self.modules.values() if m.env == env]\n    \n    def get_modules_by_tag(self, tag: str) -> List[Module]:\n        \"\"\"Get all modules with a specific tag\"\"\"\n        return [m for m in self.modules.values() if tag in m.tags]\n```\n\nThis implementation provides basic CRUD operations for modules with YAML file persistence. In a production environment, consider using a database for better scalability and concurrency handling.",
      "testStrategy": "Write unit tests to verify:\n1. Loading modules from YAML file\n2. Saving modules to YAML file\n3. CRUD operations (get, list, register, delete)\n4. Filtering by environment and tags\n5. Error handling for invalid YAML files\n6. Concurrent access handling (if applicable)",
      "priority": "high",
      "dependencies": [
        1
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 6,
      "title": "Implement ExecutorManager",
      "description": "Create the ExecutorManager component that routes execution requests to the appropriate executor based on module type.",
      "details": "Implement the ExecutorManager class to handle routing of execution requests:\n\n```python\nfrom typing import Dict, List, Any, Optional\nfrom .executor import Executor\nfrom .inline_executor import InlineExecutor\nfrom .venv_executor import VenvExecutor\nfrom .module_registry import ModuleRegistry\nfrom .models import ExecRequest, ExecResult, Module\n\nclass ExecutorManager:\n    def __init__(self, module_registry: ModuleRegistry):\n        self.module_registry = module_registry\n        self.executors: Dict[str, Executor] = {\n            \"inline\": InlineExecutor(),\n            \"venv\": VenvExecutor()\n            # Additional executors will be added in Phase 2\n        }\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        \"\"\"Execute a module with the appropriate executor\"\"\"\n        module_name = request.module\n        module = self.module_registry.get_module(module_name)\n        \n        if not module:\n            return ExecResult(\n                result_json={},\n                exit_code=1,\n                stderr=f\"Module '{module_name}' not found\",\n                stdout=\"\",\n                duration=0\n            )\n        \n        executor = self.executors.get(module.env)\n        if not executor:\n            return ExecResult(\n                result_json={},\n                exit_code=1,\n                stderr=f\"No executor available for environment '{module.env}'\",\n                stdout=\"\",\n                duration=0\n            )\n        \n        # Validate that the executor can run this module\n        if not await executor.validate(module_name):\n            return ExecResult(\n                result_json={},\n                exit_code=1,\n                stderr=f\"Module '{module_name}' cannot be executed in environment '{module.env}'\",\n                stdout=\"\",\n                duration=0\n            )\n        \n        # Execute the module\n        return await executor.execute(request)\n    \n    def register_executor(self, env: str, executor: Executor) -> None:\n        \"\"\"Register a new executor for a specific environment\"\"\"\n        self.executors[env] = executor\n    \n    def get_available_environments(self) -> List[str]:\n        \"\"\"Get a list of available execution environments\"\"\"\n        return list(self.executors.keys())\n    \n    async def cleanup(self) -> None:\n        \"\"\"Clean up all executors\"\"\"\n        for executor in self.executors.values():\n            await executor.cleanup()\n```\n\nThis implementation provides a central manager for routing execution requests to the appropriate executor based on the module's environment. It also handles validation and error reporting.",
      "testStrategy": "Write unit tests to verify:\n1. Routing requests to the correct executor\n2. Error handling for missing modules or executors\n3. Validation of modules before execution\n4. Registration of new executors\n5. Cleanup of all executors\n6. Integration with ModuleRegistry",
      "priority": "high",
      "dependencies": [
        2,
        3,
        4,
        5
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 7,
      "title": "Implement REST API with FastAPI",
      "description": "Create the REST API interface using FastAPI to expose module execution and management endpoints.",
      "details": "Implement the REST API using FastAPI:\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends, Body\nfrom typing import Dict, List, Any, Optional\nfrom pydantic import BaseModel\nfrom .models import Module, ExecRequest, ExecResult\nfrom .module_registry import ModuleRegistry\nfrom .executor_manager import ExecutorManager\n\napp = FastAPI(title=\"Operato Runner\", description=\"Python module execution platform\")\n\n# Models for API requests/responses\nclass ModuleCreate(BaseModel):\n    name: str\n    env: str\n    code: Optional[str] = None\n    path: Optional[str] = None\n    version: Optional[str] = \"0.1.0\"\n    tags: List[str] = []\n\nclass ModuleResponse(BaseModel):\n    name: str\n    env: str\n    version: str\n    created_at: str\n    tags: List[str]\n\nclass RunRequest(BaseModel):\n    input: Dict[str, Any]\n\nclass RunResponse(BaseModel):\n    result: Dict[str, Any]\n    exit_code: int\n    stderr: str\n    stdout: str\n    duration: float\n\n# Dependency injection\ndef get_module_registry():\n    return ModuleRegistry()\n\ndef get_executor_manager(module_registry: ModuleRegistry = Depends(get_module_registry)):\n    return ExecutorManager(module_registry)\n\n# Routes\n@app.get(\"/modules\", response_model=List[ModuleResponse])\nasync def list_modules(module_registry: ModuleRegistry = Depends(get_module_registry)):\n    modules = module_registry.list_modules()\n    return [\n        ModuleResponse(\n            name=m.name,\n            env=m.env,\n            version=m.version,\n            created_at=m.created_at.isoformat(),\n            tags=m.tags\n        ) for m in modules\n    ]\n\n@app.get(\"/modules/{name}\", response_model=ModuleResponse)\nasync def get_module(name: str, module_registry: ModuleRegistry = Depends(get_module_registry)):\n    module = module_registry.get_module(name)\n    if not module:\n        raise HTTPException(status_code=404, detail=f\"Module '{name}' not found\")\n    \n    return ModuleResponse(\n        name=module.name,\n        env=module.env,\n        version=module.version,\n        created_at=module.created_at.isoformat(),\n        tags=module.tags\n    )\n\n@app.post(\"/modules\", response_model=ModuleResponse, status_code=201)\nasync def create_module(\n    module_data: ModuleCreate,\n    module_registry: ModuleRegistry = Depends(get_module_registry)\n):\n    # Validate that either code or path is provided\n    if not module_data.code and not module_data.path:\n        raise HTTPException(status_code=400, detail=\"Either code or path must be provided\")\n    \n    # Create module\n    module = Module(\n        name=module_data.name,\n        env=module_data.env,\n        code=module_data.code,\n        path=module_data.path,\n        version=module_data.version,\n        tags=module_data.tags\n    )\n    \n    # Register module\n    module_registry.register_module(module)\n    \n    return ModuleResponse(\n        name=module.name,\n        env=module.env,\n        version=module.version,\n        created_at=module.created_at.isoformat(),\n        tags=module.tags\n    )\n\n@app.delete(\"/modules/{name}\", status_code=204)\nasync def delete_module(\n    name: str,\n    module_registry: ModuleRegistry = Depends(get_module_registry)\n):\n    if not module_registry.delete_module(name):\n        raise HTTPException(status_code=404, detail=f\"Module '{name}' not found\")\n    return None\n\n@app.post(\"/run/{module}\", response_model=RunResponse)\nasync def run_module(\n    module: str,\n    request: RunRequest = Body(...),\n    executor_manager: ExecutorManager = Depends(get_executor_manager)\n):\n    # Create execution request\n    exec_request = ExecRequest(\n        module=module,\n        input_json=request.input\n    )\n    \n    # Execute module\n    result = await executor_manager.execute(exec_request)\n    \n    # Return response\n    return RunResponse(\n        result=result.result_json,\n        exit_code=result.exit_code,\n        stderr=result.stderr,\n        stdout=result.stdout,\n        duration=result.duration\n    )\n\n@app.get(\"/environments\")\nasync def list_environments(\n    executor_manager: ExecutorManager = Depends(get_executor_manager)\n):\n    return {\"environments\": executor_manager.get_available_environments()}\n```\n\nThis implementation provides a complete REST API for module management and execution using FastAPI. It includes endpoints for listing, creating, retrieving, and deleting modules, as well as executing modules and listing available execution environments.",
      "testStrategy": "Write integration tests using FastAPI's TestClient to verify:\n1. Module CRUD operations\n2. Module execution\n3. Error handling for invalid requests\n4. Response format and status codes\n5. Authentication (when implemented)\n6. Performance under load",
      "priority": "high",
      "dependencies": [
        1,
        5,
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 8,
      "title": "Implement gRPC Server",
      "description": "Create the gRPC server interface to provide an alternative to REST for module execution.",
      "details": "First, define the protobuf schema in a file named `executor.proto`:\n\n```proto\nsyntax = \"proto3\";\n\npackage operato.runner;\n\nservice Executor {\n  rpc Execute(ExecRequest) returns (ExecResponse);\n  rpc ListModules(ListModulesRequest) returns (ListModulesResponse);\n  rpc GetModule(GetModuleRequest) returns (ModuleInfo);\n  rpc RegisterModule(RegisterModuleRequest) returns (ModuleInfo);\n  rpc DeleteModule(DeleteModuleRequest) returns (DeleteModuleResponse);\n}\n\nmessage ExecRequest {\n  string module = 1;\n  string json_input = 2;\n}\n\nmessage ExecResponse {\n  string result = 1;\n  int32 exit_code = 2;\n  string stderr = 3;\n  string stdout = 4;\n  double duration = 5;\n}\n\nmessage ListModulesRequest {\n  // Empty for now, could add filters later\n}\n\nmessage ListModulesResponse {\n  repeated ModuleInfo modules = 1;\n}\n\nmessage GetModuleRequest {\n  string name = 1;\n}\n\nmessage ModuleInfo {\n  string name = 1;\n  string env = 2;\n  string version = 3;\n  string created_at = 4;\n  repeated string tags = 5;\n}\n\nmessage RegisterModuleRequest {\n  string name = 1;\n  string env = 2;\n  string code = 3;\n  string path = 4;\n  string version = 5;\n  repeated string tags = 6;\n}\n\nmessage DeleteModuleRequest {\n  string name = 1;\n}\n\nmessage DeleteModuleResponse {\n  bool success = 1;\n}\n```\n\nThen, implement the gRPC server:\n\n```python\nimport json\nimport grpc\nfrom concurrent import futures\nfrom datetime import datetime\nfrom typing import Dict, List, Any\n\n# Import the generated protobuf code\nfrom .proto import executor_pb2, executor_pb2_grpc\n\nfrom .models import Module, ExecRequest as ModelExecRequest\nfrom .module_registry import ModuleRegistry\nfrom .executor_manager import ExecutorManager\n\nclass ExecutorServicer(executor_pb2_grpc.ExecutorServicer):\n    def __init__(self, module_registry: ModuleRegistry, executor_manager: ExecutorManager):\n        self.module_registry = module_registry\n        self.executor_manager = executor_manager\n    \n    async def Execute(self, request, context):\n        # Convert protobuf request to model\n        try:\n            input_json = json.loads(request.json_input)\n        except json.JSONDecodeError:\n            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)\n            context.set_details(\"Invalid JSON input\")\n            return executor_pb2.ExecResponse()\n        \n        exec_request = ModelExecRequest(\n            module=request.module,\n            input_json=input_json\n        )\n        \n        # Execute module\n        result = await self.executor_manager.execute(exec_request)\n        \n        # Convert result to protobuf response\n        return executor_pb2.ExecResponse(\n            result=json.dumps(result.result_json),\n            exit_code=result.exit_code,\n            stderr=result.stderr,\n            stdout=result.stdout,\n            duration=result.duration\n        )\n    \n    async def ListModules(self, request, context):\n        modules = self.module_registry.list_modules()\n        response = executor_pb2.ListModulesResponse()\n        \n        for module in modules:\n            module_info = executor_pb2.ModuleInfo(\n                name=module.name,\n                env=module.env,\n                version=module.version,\n                created_at=module.created_at.isoformat(),\n                tags=module.tags\n            )\n            response.modules.append(module_info)\n        \n        return response\n    \n    async def GetModule(self, request, context):\n        module = self.module_registry.get_module(request.name)\n        if not module:\n            context.set_code(grpc.StatusCode.NOT_FOUND)\n            context.set_details(f\"Module '{request.name}' not found\")\n            return executor_pb2.ModuleInfo()\n        \n        return executor_pb2.ModuleInfo(\n            name=module.name,\n            env=module.env,\n            version=module.version,\n            created_at=module.created_at.isoformat(),\n            tags=module.tags\n        )\n    \n    async def RegisterModule(self, request, context):\n        # Validate that either code or path is provided\n        if not request.code and not request.path:\n            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)\n            context.set_details(\"Either code or path must be provided\")\n            return executor_pb2.ModuleInfo()\n        \n        # Create module\n        module = Module(\n            name=request.name,\n            env=request.env,\n            code=request.code if request.code else None,\n            path=request.path if request.path else None,\n            version=request.version if request.version else \"0.1.0\",\n            tags=list(request.tags)\n        )\n        \n        # Register module\n        self.module_registry.register_module(module)\n        \n        return executor_pb2.ModuleInfo(\n            name=module.name,\n            env=module.env,\n            version=module.version,\n            created_at=module.created_at.isoformat(),\n            tags=module.tags\n        )\n    \n    async def DeleteModule(self, request, context):\n        success = self.module_registry.delete_module(request.name)\n        if not success:\n            context.set_code(grpc.StatusCode.NOT_FOUND)\n            context.set_details(f\"Module '{request.name}' not found\")\n        \n        return executor_pb2.DeleteModuleResponse(success=success)\n\ndef serve(module_registry: ModuleRegistry, executor_manager: ExecutorManager, port=50051):\n    server = grpc.aio.server(futures.ThreadPoolExecutor(max_workers=10))\n    executor_pb2_grpc.add_ExecutorServicer_to_server(\n        ExecutorServicer(module_registry, executor_manager),\n        server\n    )\n    server.add_insecure_port(f'[::]:{port}')\n    return server\n```\n\nThis implementation provides a complete gRPC server for module management and execution. It includes methods for listing, creating, retrieving, and deleting modules, as well as executing modules.",
      "testStrategy": "Write integration tests using the gRPC testing utilities to verify:\n1. Module CRUD operations\n2. Module execution\n3. Error handling for invalid requests\n4. Response format and status codes\n5. Performance under load\n6. Compatibility with different gRPC clients",
      "priority": "medium",
      "dependencies": [
        1,
        5,
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 9,
      "title": "Implement Main Application Entry Point",
      "description": "Create the main application entry point that initializes and starts both REST and gRPC servers.",
      "details": "Implement the main application entry point:\n\n```python\nimport asyncio\nimport argparse\nimport uvicorn\nfrom typing import Dict, Any\n\nfrom .module_registry import ModuleRegistry\nfrom .executor_manager import ExecutorManager\nfrom .inline_executor import InlineExecutor\nfrom .venv_executor import VenvExecutor\nfrom .api.rest import app as rest_app\nfrom .api.grpc_server import serve as serve_grpc\n\nasync def main():\n    # Parse command line arguments\n    parser = argparse.ArgumentParser(description=\"Operato Runner\")\n    parser.add_argument(\"--config\", default=\"./modules.yaml\", help=\"Path to modules configuration file\")\n    parser.add_argument(\"--rest-port\", type=int, default=8000, help=\"REST API port\")\n    parser.add_argument(\"--grpc-port\", type=int, default=50051, help=\"gRPC server port\")\n    parser.add_argument(\"--venv-path\", default=\"./venvs\", help=\"Path to virtual environments\")\n    parser.add_argument(\"--no-rest\", action=\"store_true\", help=\"Disable REST API\")\n    parser.add_argument(\"--no-grpc\", action=\"store_true\", help=\"Disable gRPC server\")\n    args = parser.parse_args()\n    \n    # Initialize module registry\n    module_registry = ModuleRegistry(config_path=args.config)\n    \n    # Initialize executor manager\n    executor_manager = ExecutorManager(module_registry)\n    \n    # Register executors\n    executor_manager.register_executor(\"inline\", InlineExecutor())\n    executor_manager.register_executor(\"venv\", VenvExecutor(venv_path=args.venv_path))\n    \n    # Set up REST app context\n    rest_app.state.module_registry = module_registry\n    rest_app.state.executor_manager = executor_manager\n    \n    # Start servers\n    tasks = []\n    \n    if not args.no_grpc:\n        # Start gRPC server\n        grpc_server = await serve_grpc(module_registry, executor_manager, port=args.grpc_port)\n        await grpc_server.start()\n        print(f\"gRPC server started on port {args.grpc_port}\")\n        tasks.append(grpc_server.wait_for_termination())\n    \n    if not args.no_rest:\n        # Start REST server in a separate thread\n        config = uvicorn.Config(rest_app, host=\"0.0.0.0\", port=args.rest_port, log_level=\"info\")\n        server = uvicorn.Server(config)\n        tasks.append(server.serve())\n        print(f\"REST API started on port {args.rest_port}\")\n    \n    # Wait for servers to complete\n    await asyncio.gather(*tasks)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThis implementation provides a main entry point that initializes the module registry and executor manager, registers the available executors, and starts both the REST and gRPC servers. It also provides command-line arguments for configuration.",
      "testStrategy": "Write integration tests to verify:\n1. Command-line argument parsing\n2. Initialization of components\n3. Starting of servers\n4. Graceful shutdown\n5. Configuration loading",
      "priority": "medium",
      "dependencies": [
        5,
        6,
        7,
        8
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 10,
      "title": "Implement CondaExecutor",
      "description": "Create the CondaExecutor that runs Python code in Conda environments.",
      "details": "Implement the CondaExecutor class that runs code in Conda environments:\n\n```python\nimport os\nimport subprocess\nimport tempfile\nimport json\nimport time\nfrom typing import Dict, Any\nfrom .executor import Executor\nfrom .models import ExecRequest, ExecResult\n\nclass CondaExecutor(Executor):\n    def __init__(self):\n        pass\n    \n    async def validate(self, module_name: str) -> bool:\n        # Check if module exists and is of type 'conda'\n        # Also verify the conda environment exists\n        try:\n            # Check if conda is installed\n            subprocess.run([\"conda\", \"--version\"], check=True, capture_output=True)\n            \n            # Check if the environment exists\n            result = subprocess.run(\n                [\"conda\", \"env\", \"list\", \"--json\"],\n                check=True,\n                capture_output=True,\n                text=True\n            )\n            envs = json.loads(result.stdout)[\"envs\"]\n            \n            # Assume environment name matches module name\n            return any(env.endswith(module_name) for env in envs)\n        except (subprocess.SubprocessError, json.JSONDecodeError):\n            return False\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        start_time = time.time()\n        module_name = request.module\n        \n        # Create temporary file for input JSON\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as input_file:\n            json.dump(request.input_json, input_file)\n            input_path = input_file.name\n        \n        # Create temporary file for output\n        output_path = tempfile.mktemp(suffix='.json')\n        \n        # Get module path from registry\n        module_path = \"\"  # Placeholder, will come from ModuleRegistry\n        \n        # Command to execute the module in conda environment\n        cmd = [\n            \"conda\", \"run\", \"-n\", module_name,\n            \"python\", \"-c\",\n            f\"import json; import sys; sys.path.append('{os.path.dirname(module_path)}'); \"\n            f\"from {os.path.basename(module_path).replace('.py', '')} import handler; \"\n            f\"with open('{input_path}', 'r') as f: input_data = json.load(f); \"\n            f\"result = handler(input_data); \"\n            f\"with open('{output_path}', 'w') as f: json.dump(result, f)\"\n        ]\n        \n        try:\n            # Execute the command\n            process = subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                timeout=60  # 1 minute timeout\n            )\n            \n            # Read the output\n            if os.path.exists(output_path):\n                with open(output_path, 'r') as f:\n                    result_json = json.load(f)\n            else:\n                result_json = {}\n                \n            exit_code = process.returncode\n            stderr = process.stderr\n            stdout = process.stdout\n            \n        except subprocess.TimeoutExpired:\n            exit_code = 124  # Standard timeout exit code\n            stderr = \"Execution timed out after 60 seconds\"\n            stdout = \"\"\n            result_json = {}\n        except Exception as e:\n            exit_code = 1\n            stderr = f\"Error executing module: {str(e)}\"\n            stdout = \"\"\n            result_json = {}\n        finally:\n            # Clean up temporary files\n            if os.path.exists(input_path):\n                os.unlink(input_path)\n            if os.path.exists(output_path):\n                os.unlink(output_path)\n        \n        duration = time.time() - start_time\n        \n        return ExecResult(\n            result_json=result_json,\n            exit_code=exit_code,\n            stderr=stderr,\n            stdout=stdout,\n            duration=duration\n        )\n    \n    async def cleanup(self) -> None:\n        # Nothing to do for cleanup in this implementation\n        pass\n        \n    @property\n    def executor_type(self) -> str:\n        return \"conda\"\n```\n\nThis implementation assumes that Conda environments are pre-created for each module. You may want to add functionality to create environments on-demand and install requirements.",
      "testStrategy": "Write integration tests to verify:\n1. Execution in Conda environments\n2. Proper handling of dependencies within the environment\n3. Correct passing of input/output between main process and environment\n4. Timeout handling for long-running processes\n5. Error handling for missing environments or modules\n6. Resource cleanup after execution",
      "priority": "low",
      "dependencies": [
        1,
        2,
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 11,
      "title": "Implement DockerExecutor",
      "description": "Create the DockerExecutor that runs Python code in Docker containers.",
      "details": "Implement the DockerExecutor class that runs code in Docker containers:\n\n```python\nimport os\nimport tempfile\nimport json\nimport time\nimport docker\nfrom typing import Dict, Any\nfrom .executor import Executor\nfrom .models import ExecRequest, ExecResult\n\nclass DockerExecutor(Executor):\n    def __init__(self, base_image=\"python:3.10-slim\"):\n        self.client = docker.from_env()\n        self.base_image = base_image\n    \n    async def validate(self, module_name: str) -> bool:\n        # Check if module exists and is of type 'docker'\n        # Also verify Docker is available\n        try:\n            self.client.ping()\n            return True  # Simplified validation, should check if module is compatible\n        except Exception:\n            return False\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        start_time = time.time()\n        module_name = request.module\n        \n        # Create temporary directory for mounting\n        temp_dir = tempfile.mkdtemp()\n        \n        # Create input file\n        input_path = os.path.join(temp_dir, \"input.json\")\n        with open(input_path, \"w\") as f:\n            json.dump(request.input_json, f)\n        \n        # Create output file path\n        output_path = os.path.join(temp_dir, \"output.json\")\n        \n        # Get module code from registry\n        code = \"\"  # Placeholder, will come from ModuleRegistry\n        \n        # Create Python script file\n        script_path = os.path.join(temp_dir, \"script.py\")\n        with open(script_path, \"w\") as f:\n            f.write(code)\n            f.write(\"\\n\\n\")\n            f.write(\"if __name__ == '__main__':\\n\")\n            f.write(\"    import json\\n\")\n            f.write(\"    with open('/data/input.json', 'r') as f:\\n\")\n            f.write(\"        input_data = json.load(f)\\n\")\n            f.write(\"    result = handler(input_data)\\n\")\n            f.write(\"    with open('/data/output.json', 'w') as f:\\n\")\n            f.write(\"        json.dump(result, f)\\n\")\n        \n        # Run Docker container\n        container = None\n        try:\n            container = self.client.containers.run(\n                self.base_image,\n                command=[\"python\", \"/data/script.py\"],\n                volumes={temp_dir: {\"bind\": \"/data\", \"mode\": \"rw\"}},\n                detach=True,\n                mem_limit=\"512m\",  # Limit memory usage\n                cpu_period=100000,  # Limit CPU usage\n                cpu_quota=50000,    # 50% of CPU\n                network_mode=\"none\"  # Disable network access\n            )\n            \n            # Wait for container to finish with timeout\n            exit_code = container.wait(timeout=60)[\"StatusCode\"]\n            \n            # Get logs\n            logs = container.logs(stdout=True, stderr=True).decode(\"utf-8\")\n            stdout = \"\"\n            stderr = \"\"\n            \n            # Split logs into stdout and stderr (simplified)\n            if exit_code == 0:\n                stdout = logs\n            else:\n                stderr = logs\n            \n            # Read output file if it exists\n            if os.path.exists(output_path):\n                with open(output_path, \"r\") as f:\n                    result_json = json.load(f)\n            else:\n                result_json = {}\n                \n        except docker.errors.ContainerError as e:\n            exit_code = e.exit_status\n            stderr = str(e)\n            stdout = \"\"\n            result_json = {}\n        except Exception as e:\n            exit_code = 1\n            stderr = f\"Error executing module: {str(e)}\"\n            stdout = \"\"\n            result_json = {}\n        finally:\n            # Clean up container\n            if container:\n                try:\n                    container.remove(force=True)\n                except Exception:\n                    pass\n            \n            # Clean up temporary directory\n            import shutil\n            shutil.rmtree(temp_dir, ignore_errors=True)\n        \n        duration = time.time() - start_time\n        \n        return ExecResult(\n            result_json=result_json,\n            exit_code=exit_code,\n            stderr=stderr,\n            stdout=stdout,\n            duration=duration\n        )\n    \n    async def cleanup(self) -> None:\n        # Clean up any dangling containers\n        try:\n            containers = self.client.containers.list(all=True, filters={\"label\": \"operato-runner\"})\n            for container in containers:\n                container.remove(force=True)\n        except Exception:\n            pass\n        \n    @property\n    def executor_type(self) -> str:\n        return \"docker\"\n```\n\nThis implementation uses the Docker Python SDK to run code in containers. It creates temporary files for input and output, mounts them into the container, and runs the code in an isolated environment with resource limits.",
      "testStrategy": "Write integration tests to verify:\n1. Execution in Docker containers\n2. Proper handling of dependencies within the container\n3. Correct passing of input/output between host and container\n4. Timeout handling for long-running containers\n5. Resource limits enforcement\n6. Network isolation\n7. Cleanup of containers and temporary files",
      "priority": "low",
      "dependencies": [
        1,
        2,
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 12,
      "title": "Implement Module Execution History",
      "description": "Create a system to track and store the history of module executions for auditing and debugging.",
      "details": "Implement the execution history tracking system:\n\n```python\nimport os\nimport json\nimport sqlite3\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\nfrom .models import ExecResult\n\nclass ExecutionHistory:\n    def __init__(self, db_path=\"./executions.db\"):\n        self.db_path = db_path\n        self._init_db()\n    \n    def _init_db(self):\n        \"\"\"Initialize the database if it doesn't exist\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # Create executions table\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS executions (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            module_name TEXT NOT NULL,\n            timestamp TEXT NOT NULL,\n            duration REAL NOT NULL,\n            exit_code INTEGER NOT NULL,\n            input_json TEXT NOT NULL,\n            result_json TEXT NOT NULL,\n            stdout TEXT,\n            stderr TEXT\n        )\n        \"\"\")\n        \n        conn.commit()\n        conn.close()\n    \n    def record_execution(self, module_name: str, input_json: Dict[str, Any], result: ExecResult) -> int:\n        \"\"\"Record an execution in the database\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        timestamp = datetime.now().isoformat()\n        \n        cursor.execute(\"\"\"\n        INSERT INTO executions \n        (module_name, timestamp, duration, exit_code, input_json, result_json, stdout, stderr)\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n        \"\"\", (\n            module_name,\n            timestamp,\n            result.duration,\n            result.exit_code,\n            json.dumps(input_json),\n            json.dumps(result.result_json),\n            result.stdout,\n            result.stderr\n        ))\n        \n        execution_id = cursor.lastrowid\n        \n        conn.commit()\n        conn.close()\n        \n        return execution_id\n    \n    def get_execution(self, execution_id: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Get an execution by ID\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n        \n        cursor.execute(\"SELECT * FROM executions WHERE id = ?\", (execution_id,))\n        row = cursor.fetchone()\n        \n        conn.close()\n        \n        if not row:\n            return None\n        \n        return {\n            \"id\": row[\"id\"],\n            \"module_name\": row[\"module_name\"],\n            \"timestamp\": row[\"timestamp\"],\n            \"duration\": row[\"duration\"],\n            \"exit_code\": row[\"exit_code\"],\n            \"input_json\": json.loads(row[\"input_json\"]),\n            \"result_json\": json.loads(row[\"result_json\"]),\n            \"stdout\": row[\"stdout\"],\n            \"stderr\": row[\"stderr\"]\n        }\n    \n    def list_executions(self, module_name: Optional[str] = None, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:\n        \"\"\"List executions, optionally filtered by module name\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n        \n        if module_name:\n            cursor.execute(\"\"\"\n            SELECT id, module_name, timestamp, duration, exit_code\n            FROM executions\n            WHERE module_name = ?\n            ORDER BY timestamp DESC\n            LIMIT ? OFFSET ?\n            \"\"\", (module_name, limit, offset))\n        else:\n            cursor.execute(\"\"\"\n            SELECT id, module_name, timestamp, duration, exit_code\n            FROM executions\n            ORDER BY timestamp DESC\n            LIMIT ? OFFSET ?\n            \"\"\", (limit, offset))\n        \n        rows = cursor.fetchall()\n        \n        conn.close()\n        \n        return [{\n            \"id\": row[\"id\"],\n            \"module_name\": row[\"module_name\"],\n            \"timestamp\": row[\"timestamp\"],\n            \"duration\": row[\"duration\"],\n            \"exit_code\": row[\"exit_code\"]\n        } for row in rows]\n    \n    def get_module_stats(self, module_name: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a module\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n        SELECT \n            COUNT(*) as total_executions,\n            AVG(duration) as avg_duration,\n            MIN(duration) as min_duration,\n            MAX(duration) as max_duration,\n            SUM(CASE WHEN exit_code = 0 THEN 1 ELSE 0 END) as successful_executions,\n            SUM(CASE WHEN exit_code != 0 THEN 1 ELSE 0 END) as failed_executions\n        FROM executions\n        WHERE module_name = ?\n        \"\"\", (module_name,))\n        \n        row = cursor.fetchone()\n        \n        conn.close()\n        \n        if not row:\n            return {\n                \"total_executions\": 0,\n                \"avg_duration\": 0,\n                \"min_duration\": 0,\n                \"max_duration\": 0,\n                \"successful_executions\": 0,\n                \"failed_executions\": 0,\n                \"success_rate\": 0\n            }\n        \n        total = row[0]\n        success_rate = (row[4] / total) * 100 if total > 0 else 0\n        \n        return {\n            \"total_executions\": row[0],\n            \"avg_duration\": row[1],\n            \"min_duration\": row[2],\n            \"max_duration\": row[3],\n            \"successful_executions\": row[4],\n            \"failed_executions\": row[5],\n            \"success_rate\": success_rate\n        }\n```\n\nThis implementation provides a system for tracking and storing execution history in a SQLite database. It includes methods for recording executions, retrieving execution details, listing executions, and getting statistics for a module.",
      "testStrategy": "Write unit tests to verify:\n1. Database initialization\n2. Recording executions\n3. Retrieving execution details\n4. Listing executions with filtering and pagination\n5. Calculating module statistics\n6. Handling of large result sets\n7. Concurrent access (if applicable)",
      "priority": "medium",
      "dependencies": [
        1,
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 13,
      "title": "Implement Retry Policy for Failed Executions",
      "description": "Create a retry mechanism for handling transient failures during module execution.",
      "details": "Implement a retry policy for handling transient failures:\n\n```python\nimport asyncio\nfrom typing import Dict, Any, Optional, Callable, TypeVar, Generic\nfrom .models import ExecRequest, ExecResult\n\nT = TypeVar('T')\n\nclass RetryPolicy(Generic[T]):\n    def __init__(self, max_retries: int = 3, delay: float = 1.0, backoff_factor: float = 2.0):\n        self.max_retries = max_retries\n        self.delay = delay\n        self.backoff_factor = backoff_factor\n    \n    async def execute_with_retry(self, func: Callable[..., T], *args, **kwargs) -> T:\n        \"\"\"Execute a function with retry logic\"\"\"\n        last_exception = None\n        current_delay = self.delay\n        \n        for attempt in range(self.max_retries + 1):\n            try:\n                return await func(*args, **kwargs)\n            except Exception as e:\n                last_exception = e\n                \n                if attempt < self.max_retries:\n                    # Wait before retrying\n                    await asyncio.sleep(current_delay)\n                    current_delay *= self.backoff_factor\n                else:\n                    # Max retries reached, re-raise the exception\n                    raise\n\nclass RetryableExecutorManager:\n    def __init__(self, executor_manager, retry_policy: Optional[RetryPolicy] = None):\n        self.executor_manager = executor_manager\n        self.retry_policy = retry_policy or RetryPolicy()\n    \n    async def execute(self, request: ExecRequest) -> ExecResult:\n        \"\"\"Execute a module with retry logic\"\"\"\n        try:\n            return await self.retry_policy.execute_with_retry(\n                self.executor_manager.execute,\n                request\n            )\n        except Exception as e:\n            # If all retries fail, return an error result\n            return ExecResult(\n                result_json={},\n                exit_code=1,\n                stderr=f\"Failed after {self.retry_policy.max_retries} retries: {str(e)}\",\n                stdout=\"\",\n                duration=0\n            )\n    \n    # Delegate other methods to the underlying executor manager\n    def register_executor(self, env: str, executor) -> None:\n        self.executor_manager.register_executor(env, executor)\n    \n    def get_available_environments(self):\n        return self.executor_manager.get_available_environments()\n    \n    async def cleanup(self) -> None:\n        await self.executor_manager.cleanup()\n```\n\nThis implementation provides a generic retry policy that can be applied to any async function, as well as a retryable executor manager that wraps the standard executor manager with retry logic. The retry policy includes configurable parameters for maximum retries, initial delay, and backoff factor.",
      "testStrategy": "Write unit tests to verify:\n1. Successful retry after transient failures\n2. Giving up after max retries\n3. Proper backoff delay between retries\n4. Error reporting after all retries fail\n5. Integration with executor manager",
      "priority": "low",
      "dependencies": [
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 14,
      "title": "Implement Authentication and Authorization",
      "description": "Add authentication and authorization to the REST and gRPC APIs to secure access to the system.",
      "details": "Implement authentication and authorization for the REST API using JWT tokens:\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends, Security\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom jose import jwt, JWTError\nfrom pydantic import BaseModel\nfrom typing import Optional, List, Dict, Any\nimport os\nfrom datetime import datetime, timedelta\n\n# Models\nclass Token(BaseModel):\n    access_token: str\n    token_type: str\n\nclass TokenData(BaseModel):\n    username: Optional[str] = None\n    scopes: List[str] = []\n\nclass User(BaseModel):\n    username: str\n    disabled: Optional[bool] = None\n    scopes: List[str] = []\n\n# Configuration\nSECRET_KEY = os.getenv(\"JWT_SECRET_KEY\", \"your-secret-key\")\nALGORITHM = \"HS256\"\nACCESS_TOKEN_EXPIRE_MINUTES = 30\n\n# Security\nsecurity = HTTPBearer()\n\n# Fake user database for demonstration\nfake_users_db = {\n    \"admin\": {\n        \"username\": \"admin\",\n        \"password\": \"password\",  # In production, use hashed passwords\n        \"disabled\": False,\n        \"scopes\": [\"modules:read\", \"modules:write\", \"execute:all\"]\n    },\n    \"user\": {\n        \"username\": \"user\",\n        \"password\": \"password\",\n        \"disabled\": False,\n        \"scopes\": [\"modules:read\", \"execute:limited\"]\n    }\n}\n\n# Functions\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.utcnow() + expires_delta\n    else:\n        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\n    return encoded_jwt\n\nasync def get_current_user(credentials: HTTPAuthorizationCredentials = Security(security)):\n    credentials_exception = HTTPException(\n        status_code=401,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    try:\n        token = credentials.credentials\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n        username: str = payload.get(\"sub\")\n        if username is None:\n            raise credentials_exception\n        token_scopes = payload.get(\"scopes\", [])\n        token_data = TokenData(username=username, scopes=token_scopes)\n    except JWTError:\n        raise credentials_exception\n    user = fake_users_db.get(token_data.username)\n    if user is None:\n        raise credentials_exception\n    return User(username=user[\"username\"], disabled=user[\"disabled\"], scopes=user[\"scopes\"])\n\nasync def get_current_active_user(current_user: User = Depends(get_current_user)):\n    if current_user.disabled:\n        raise HTTPException(status_code=400, detail=\"Inactive user\")\n    return current_user\n\ndef has_scope(required_scope: str):\n    async def _has_scope(current_user: User = Depends(get_current_active_user)):\n        if required_scope not in current_user.scopes:\n            raise HTTPException(\n                status_code=403,\n                detail=f\"Not enough permissions. Required scope: {required_scope}\"\n            )\n        return current_user\n    return _has_scope\n\n# API routes\n@app.post(\"/token\", response_model=Token)\nasync def login_for_access_token(username: str, password: str):\n    user = fake_users_db.get(username)\n    if not user or user[\"password\"] != password:  # In production, use proper password verification\n        raise HTTPException(\n            status_code=401,\n            detail=\"Incorrect username or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\n    access_token = create_access_token(\n        data={\"sub\": user[\"username\"], \"scopes\": user[\"scopes\"]},\n        expires_delta=access_token_expires\n    )\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}\n\n# Secure the existing endpoints\n@app.get(\"/modules\", response_model=List[ModuleResponse])\nasync def list_modules(\n    current_user: User = Depends(has_scope(\"modules:read\")),\n    module_registry: ModuleRegistry = Depends(get_module_registry)\n):\n    modules = module_registry.list_modules()\n    return [\n        ModuleResponse(\n            name=m.name,\n            env=m.env,\n            version=m.version,\n            created_at=m.created_at.isoformat(),\n            tags=m.tags\n        ) for m in modules\n    ]\n\n@app.post(\"/modules\", response_model=ModuleResponse, status_code=201)\nasync def create_module(\n    module_data: ModuleCreate,\n    current_user: User = Depends(has_scope(\"modules:write\")),\n    module_registry: ModuleRegistry = Depends(get_module_registry)\n):\n    # Implementation remains the same\n    ...\n\n@app.post(\"/run/{module}\", response_model=RunResponse)\nasync def run_module(\n    module: str,\n    request: RunRequest = Body(...),\n    current_user: User = Depends(has_scope(\"execute:all\")),  # Or check for specific module permissions\n    executor_manager: ExecutorManager = Depends(get_executor_manager)\n):\n    # Implementation remains the same\n    ...\n```\n\nFor gRPC, implement authentication using interceptors:\n\n```python\nimport grpc\nfrom jose import jwt, JWTError\nfrom typing import Dict, Any, Callable\n\n# Configuration (should be shared with REST API)\nSECRET_KEY = \"your-secret-key\"\nALGORITHM = \"HS256\"\n\nclass AuthInterceptor(grpc.ServerInterceptor):\n    def __init__(self):\n        def abort(ignored_request, context):\n            context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Invalid or missing token\")\n        \n        self._abort_handler = grpc.unary_unary_rpc_method_handler(abort)\n    \n    def intercept_service(self, continuation, handler_call_details):\n        # Extract metadata\n        metadata = dict(handler_call_details.invocation_metadata)\n        \n        # Check for authorization header\n        auth_header = metadata.get(\"authorization\", \"\")\n        if not auth_header.startswith(\"Bearer \"):\n            return self._abort_handler\n        \n        # Extract and validate token\n        token = auth_header[7:]  # Remove \"Bearer \" prefix\n        try:\n            payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n            # Add user info to context for later use\n            context = grpc.ServicerContext()\n            context.user = payload\n            # Continue with the RPC\n            return continuation(handler_call_details)\n        except JWTError:\n            return self._abort_handler\n\n# Update the gRPC server creation\ndef serve(module_registry, executor_manager, port=50051):\n    server = grpc.aio.server(\n        futures.ThreadPoolExecutor(max_workers=10),\n        interceptors=[AuthInterceptor()]\n    )\n    executor_pb2_grpc.add_ExecutorServicer_to_server(\n        ExecutorServicer(module_registry, executor_manager),\n        server\n    )\n    server.add_insecure_port(f'[::]:{port}')\n    return server\n```\n\nThis implementation provides basic authentication and authorization for both REST and gRPC APIs using JWT tokens. For the REST API, it uses FastAPI's dependency injection system to secure endpoints with scopes. For gRPC, it uses interceptors to validate tokens before processing requests.",
      "testStrategy": "Write integration tests to verify:\n1. Token generation and validation\n2. Access control based on scopes\n3. Rejection of invalid or expired tokens\n4. Proper error responses for unauthorized requests\n5. Integration with both REST and gRPC APIs",
      "priority": "medium",
      "dependencies": [
        7,
        8
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 15,
      "title": "Create Deployment Configuration",
      "description": "Prepare deployment configuration for Kubernetes using Helm charts.",
      "details": "Create a Helm chart for deploying the application to Kubernetes. First, create the directory structure:\n\n```\noperato-runner/\n Chart.yaml\n values.yaml\n templates/\n    deployment.yaml\n    service.yaml\n    configmap.yaml\n    secret.yaml\n    _helpers.tpl\n .helmignore\n```\n\nThen, create the Chart.yaml file:\n\n```yaml\napiVersion: v2\nname: operato-runner\ndescription: A Helm chart for Operato Runner\ntype: application\nversion: 0.1.0\nappVersion: 0.1.0\n```\n\nCreate the values.yaml file with default configuration:\n\n```yaml\n# Default values for operato-runner\nreplicaCount: 1\n\nimage:\n  repository: operato/runner\n  pullPolicy: IfNotPresent\n  tag: \"latest\"\n\nimagePullSecrets: []\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  create: true\n  annotations: {}\n  name: \"\"\n\npodAnnotations: {}\n\npodSecurityContext: {}\n\nsecurityContext: {}\n\nservice:\n  type: ClusterIP\n  restPort: 8000\n  grpcPort: 50051\n\ningress:\n  enabled: false\n  className: \"\"\n  annotations: {}\n  hosts:\n    - host: chart-example.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n  tls: []\n\nresources:\n  limits:\n    cpu: 1000m\n    memory: 1Gi\n  requests:\n    cpu: 500m\n    memory: 512Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 80\n\nnodeSelector: {}\n\ntolerations: []\n\naffinity: {}\n\nconfig:\n  modulesPath: /app/modules.yaml\n  venvPath: /app/venvs\n  executionHistoryPath: /app/executions.db\n  jwtSecret: change-me-in-production\n\npersistence:\n  enabled: true\n  storageClass: \"\"\n  accessMode: ReadWriteOnce\n  size: 10Gi\n```\n\nCreate the deployment.yaml template:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include \"operato-runner.fullname\" . }}\n  labels:\n    {{- include \"operato-runner.labels\" . | nindent 4 }}\nspec:\n  {{- if not .Values.autoscaling.enabled }}\n  replicas: {{ .Values.replicaCount }}\n  {{- end }}\n  selector:\n    matchLabels:\n      {{- include \"operato-runner.selectorLabels\" . | nindent 6 }}\n  template:\n    metadata:\n      {{- with .Values.podAnnotations }}\n      annotations:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      labels:\n        {{- include \"operato-runner.selectorLabels\" . | nindent 8 }}\n    spec:\n      {{- with .Values.imagePullSecrets }}\n      imagePullSecrets:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      serviceAccountName: {{ include \"operato-runner.serviceAccountName\" . }}\n      securityContext:\n        {{- toYaml .Values.podSecurityContext | nindent 8 }}\n      containers:\n        - name: {{ .Chart.Name }}\n          securityContext:\n            {{- toYaml .Values.securityContext | nindent 12 }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          env:\n            - name: JWT_SECRET_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: {{ include \"operato-runner.fullname\" . }}\n                  key: jwt-secret\n          args:\n            - \"--config=$(CONFIG_PATH)\"\n            - \"--venv-path=$(VENV_PATH)\"\n            - \"--rest-port=$(REST_PORT)\"\n            - \"--grpc-port=$(GRPC_PORT)\"\n          env:\n            - name: CONFIG_PATH\n              value: {{ .Values.config.modulesPath }}\n            - name: VENV_PATH\n              value: {{ .Values.config.venvPath }}\n            - name: REST_PORT\n              value: \"{{ .Values.service.restPort }}\"\n            - name: GRPC_PORT\n              value: \"{{ .Values.service.grpcPort }}\"\n          ports:\n            - name: rest\n              containerPort: {{ .Values.service.restPort }}\n              protocol: TCP\n            - name: grpc\n              containerPort: {{ .Values.service.grpcPort }}\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: rest\n          readinessProbe:\n            httpGet:\n              path: /health\n              port: rest\n          resources:\n            {{- toYaml .Values.resources | nindent 12 }}\n          volumeMounts:\n            - name: data\n              mountPath: /app/data\n      {{- with .Values.nodeSelector }}\n      nodeSelector:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.affinity }}\n      affinity:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.tolerations }}\n      tolerations:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      volumes:\n        - name: data\n          {{- if .Values.persistence.enabled }}\n          persistentVolumeClaim:\n            claimName: {{ include \"operato-runner.fullname\" . }}\n          {{- else }}\n          emptyDir: {}\n          {{- end }}\n```\n\nCreate the service.yaml template:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \"operato-runner.fullname\" . }}\n  labels:\n    {{- include \"operato-runner.labels\" . | nindent 4 }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.restPort }}\n      targetPort: rest\n      protocol: TCP\n      name: rest\n    - port: {{ .Values.service.grpcPort }}\n      targetPort: grpc\n      protocol: TCP\n      name: grpc\n  selector:\n    {{- include \"operato-runner.selectorLabels\" . | nindent 4 }}\n```\n\nCreate the secret.yaml template:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ include \"operato-runner.fullname\" . }}\n  labels:\n    {{- include \"operato-runner.labels\" . | nindent 4 }}\ntype: Opaque\ndata:\n  jwt-secret: {{ .Values.config.jwtSecret | b64enc }}\n```\n\nCreate the persistent volume claim if persistence is enabled:\n\n```yaml\n{{- if .Values.persistence.enabled }}\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: {{ include \"operato-runner.fullname\" . }}\n  labels:\n    {{- include \"operato-runner.labels\" . | nindent 4 }}\nspec:\n  accessModes:\n    - {{ .Values.persistence.accessMode }}\n  {{- if .Values.persistence.storageClass }}\n  storageClassName: {{ .Values.persistence.storageClass }}\n  {{- end }}\n  resources:\n    requests:\n      storage: {{ .Values.persistence.size }}\n{{- end }}\n```\n\nCreate the _helpers.tpl file with common template functions:\n\n```\n{{/*\nExpand the name of the chart.\n*/}}\n{{- define \"operato-runner.name\" -}}\n{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCreate a default fully qualified app name.\n*/}}\n{{- define \"operato-runner.fullname\" -}}\n{{- if .Values.fullnameOverride }}\n{{- .Values.fullnameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- $name := default .Chart.Name .Values.nameOverride }}\n{{- if contains $name .Release.Name }}\n{{- .Release.Name | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- printf \"%s-%s\" .Release.Name $name | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n{{- end }}\n{{- end }}\n\n{{/*\nCreate chart name and version as used by the chart label.\n*/}}\n{{- define \"operato-runner.chart\" -}}\n{{- printf \"%s-%s\" .Chart.Name .Chart.Version | replace \"+\" \"_\" | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCommon labels\n*/}}\n{{- define \"operato-runner.labels\" -}}\nhelm.sh/chart: {{ include \"operato-runner.chart\" . }}\n{{ include \"operato-runner.selectorLabels\" . }}\n{{- if .Chart.AppVersion }}\napp.kubernetes.io/version: {{ .Chart.AppVersion | quote }}\n{{- end }}\napp.kubernetes.io/managed-by: {{ .Release.Service }}\n{{- end }}\n\n{{/*\nSelector labels\n*/}}\n{{- define \"operato-runner.selectorLabels\" -}}\napp.kubernetes.io/name: {{ include \"operato-runner.name\" . }}\napp.kubernetes.io/instance: {{ .Release.Name }}\n{{- end }}\n\n{{/*\nCreate the name of the service account to use\n*/}}\n{{- define \"operato-runner.serviceAccountName\" -}}\n{{- if .Values.serviceAccount.create }}\n{{- default (include \"operato-runner.fullname\" .) .Values.serviceAccount.name }}\n{{- else }}\n{{- default \"default\" .Values.serviceAccount.name }}\n{{- end }}\n{{- end }}\n```\n\nThis Helm chart provides a complete deployment configuration for Kubernetes, including deployment, service, secrets, and persistent volume claims. It can be customized through the values.yaml file to suit different environments.",
      "testStrategy": "Test the Helm chart using:\n1. Helm lint to validate the chart structure\n2. Helm template to generate and validate the Kubernetes manifests\n3. Helm install --dry-run to simulate installation\n4. Deploy to a test Kubernetes cluster and verify functionality\n5. Test scaling and resource limits\n6. Verify persistence across pod restarts",
      "priority": "low",
      "dependencies": [
        9
      ],
      "status": "done",
      "subtasks": []
    },
    {
      "id": 16,
      "title": "Task #16: Implement Server Provisioning Automation with FastAPI and React",
      "description": "Develop an automated server provisioning system with a FastAPI backend and React frontend that handles module deployment, version management, and monitoring with comprehensive authentication and authorization.",
      "details": "This task involves building a complete server provisioning automation system with the following components:\n\n1. Backend (FastAPI + PostgreSQL):\n   - Create database models for modules, versions, deployments, and user permissions\n   - Implement RESTful API endpoints for module CRUD operations\n   - Design and implement JWT-based authentication/authorization system\n   - Develop module upload, validation, and storage functionality\n   - Create version management system with rollback capabilities\n   - Implement database migration system using Alembic\n   - Add logging and monitoring endpoints for system health\n\n2. Frontend (React + TypeScript + MUI):\n   - Create responsive admin dashboard UI\n   - Implement module upload and management interface\n   - Build deployment configuration screens\n   - Design monitoring dashboards for deployed modules\n   - Implement user management and permission controls\n   - Add version history and comparison views\n   - Create notification system for deployment events\n\n3. DevOps Integration:\n   - Set up CI/CD pipeline for the provisioning system itself\n   - Implement automated testing for both frontend and backend\n   - Create Docker containers for consistent deployment\n   - Design the system to work with existing Task #15 Kubernetes/Helm configuration\n\n4. Security Considerations:\n   - Implement role-based access control (RBAC)\n   - Add audit logging for all administrative actions\n   - Ensure secure storage of credentials and secrets\n   - Implement rate limiting and protection against common attacks\n\nThe system should be designed to be modular, allowing for future extensions and integrations with other systems.",
      "testStrategy": "Testing for this task should be comprehensive and include:\n\n1. Unit Testing:\n   - Backend: Test all API endpoints using pytest\n   - Frontend: Test React components with Jest and React Testing Library\n   - Test authentication flows and permission checks\n   - Validate database models and migrations\n\n2. Integration Testing:\n   - Test the complete module upload, validation, and deployment flow\n   - Verify JWT token generation, validation, and refresh\n   - Test database migrations and rollback procedures\n   - Validate frontend-backend integration points\n\n3. End-to-End Testing:\n   - Create Cypress tests for critical user journeys\n   - Test the complete provisioning workflow from UI to actual deployment\n   - Verify monitoring and alerting functionality\n   - Test permission boundaries and access controls\n\n4. Security Testing:\n   - Perform penetration testing on authentication mechanisms\n   - Test for common vulnerabilities (SQL injection, XSS, CSRF)\n   - Verify proper handling of sensitive information\n\n5. Performance Testing:\n   - Test system under load, especially during multiple concurrent deployments\n   - Measure and optimize database query performance\n   - Test UI responsiveness with large datasets\n\n6. Acceptance Criteria:\n   - Admin users can upload, version, and deploy modules through the UI\n   - Role-based permissions correctly restrict access to features\n   - Modules can be monitored for health and performance\n   - System maintains audit logs of all administrative actions\n   - CI/CD pipeline successfully deploys changes to the system\n   - Database migrations run successfully without data loss",
      "status": "pending",
      "dependencies": [],
      "priority": "medium",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement FastAPI Backend Core with Database Models and Authentication",
          "description": "Set up the FastAPI backend with PostgreSQL integration, create database models, and implement JWT-based authentication and authorization system.",
          "dependencies": [],
          "details": "1. Initialize FastAPI project structure with proper dependency management\n2. Set up PostgreSQL connection using SQLAlchemy ORM\n3. Create database models for users, roles, modules, versions, and deployments\n4. Implement Alembic for database migrations\n5. Develop JWT authentication with token generation, validation, and refresh mechanisms\n6. Create user registration, login, and profile management endpoints\n7. Implement role-based access control (RBAC) middleware\n8. Set up password hashing and security best practices\n9. Add audit logging for authentication events",
          "status": "pending",
          "testStrategy": "Write unit tests for model validation, authentication flows, and authorization rules. Use pytest with database fixtures for integration testing."
        },
        {
          "id": 2,
          "title": "Develop Module Management and Deployment API Endpoints",
          "description": "Create RESTful API endpoints for module CRUD operations, version management, deployment configuration, and system monitoring.",
          "dependencies": [
            1
          ],
          "details": "1. Implement module upload endpoint with file validation and storage\n2. Create CRUD endpoints for modules with proper error handling\n3. Develop version management system with tagging and rollback capabilities\n4. Implement deployment configuration endpoints with validation\n5. Create system health and monitoring endpoints\n6. Add logging for all administrative actions\n7. Implement rate limiting and security protections\n8. Create API documentation using OpenAPI/Swagger\n9. Develop notification system for deployment events",
          "status": "pending",
          "testStrategy": "Create integration tests for each endpoint using pytest. Test file uploads, version management, and deployment workflows with mock data."
        },
        {
          "id": 3,
          "title": "Build React Frontend Core with Authentication and Dashboard",
          "description": "Develop the React frontend with TypeScript and Material-UI, implementing authentication flows and the main dashboard structure.",
          "dependencies": [
            1
          ],
          "details": "1. Set up React project with TypeScript, MUI, and state management (Redux or Context API)\n2. Create responsive layout with navigation and theme support\n3. Implement login, registration, and user profile screens\n4. Develop authentication state management with JWT storage and refresh\n5. Create protected routes based on user roles\n6. Build main dashboard with overview statistics\n7. Implement notification system UI components\n8. Add error handling and user feedback mechanisms\n9. Create reusable UI components for consistent design",
          "status": "pending",
          "testStrategy": "Use React Testing Library and Jest for component testing. Test authentication flows, protected routes, and responsive layouts."
        },
        {
          "id": 4,
          "title": "Implement Module Management and Monitoring UI",
          "description": "Create the frontend interfaces for module upload, version management, deployment configuration, and system monitoring dashboards.",
          "dependencies": [
            2,
            3
          ],
          "details": "1. Build module upload interface with drag-and-drop functionality\n2. Create module listing and detail views with filtering and search\n3. Implement version history and comparison views\n4. Develop deployment configuration screens with validation\n5. Build monitoring dashboards with charts and real-time updates\n6. Create user management and permission control interfaces\n7. Implement audit log viewer with filtering\n8. Add version rollback UI and confirmation flows\n9. Develop system health visualization components",
          "status": "pending",
          "testStrategy": "Test complex UI interactions with user event simulations. Create snapshot tests for UI components and integration tests for data flow between components."
        },
        {
          "id": 5,
          "title": "Set up DevOps Pipeline and Security Hardening",
          "description": "Implement CI/CD pipeline, containerization, automated testing, and security hardening for the entire system.",
          "dependencies": [
            2,
            4
          ],
          "details": "1. Create Docker containers for both frontend and backend\n2. Set up Docker Compose for local development\n3. Implement CI/CD pipeline using GitHub Actions or similar\n4. Configure automated testing in the pipeline\n5. Set up staging and production deployment workflows\n6. Implement secure storage for credentials and secrets\n7. Add security headers and protection against common attacks\n8. Configure integration with existing Kubernetes/Helm setup from Task #15\n9. Create comprehensive documentation for deployment and maintenance",
          "status": "pending",
          "testStrategy": "Implement end-to-end testing with Cypress or similar tools. Test deployment workflows in staging environment. Conduct security scanning and penetration testing."
        },
        {
          "id": 6,
          "title": "FastAPI      ",
          "description": "FastAPI  , poetry/pip    .    .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 7,
          "title": "PostgreSQL   SQLAlchemy ",
          "description": "PostgreSQL  , SQLAlchemy ORM . DB      .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 8,
          "title": "User   ",
          "description": "(User)   SQLAlchemy   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 9,
          "title": "Role   ",
          "description": "(Role)   SQLAlchemy   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 10,
          "title": "Module   ",
          "description": "(Module)   SQLAlchemy   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 11,
          "title": "Version   ",
          "description": "(Version)   SQLAlchemy   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 12,
          "title": "Deployment   ",
          "description": "(Deployment)   SQLAlchemy   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 13,
          "title": "Alembic   ",
          "description": "DB    Alembic   ,    .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 14,
          "title": "JWT /  ",
          "description": "JWT  , ,   .   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 15,
          "title": " // API ",
          "description": ", ,  / API .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 16,
          "title": "RBAC  ",
          "description": "   (RBAC)      .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 17,
          "title": " / ",
          "description": "     .    best practice .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 18,
          "title": " /   ",
          "description": "      /   .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 19,
          "title": "  (pytest)",
          "description": "FastAPI      pytest .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        },
        {
          "id": 20,
          "title": "API (OpenAPI)",
          "description": "FastAPI OpenAPI    API  .",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 16
        }
      ]
    }
  ]
}